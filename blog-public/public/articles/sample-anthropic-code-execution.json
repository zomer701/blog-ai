{
  "id": "sample-anthropic-code-execution",
  "source": "Anthropic",
  "source_url": "https://www.anthropic.com/engineering/code-execution-with-mcp",
  "title": "Code execution with MCP: Building more efficient agents",
  "author": "Anthropic Engineering",
  "published_date": "2025-11-04T00:00:00Z",
  "scraped_at": 1733203200000,
  "status": "published",
  "content": {
    "original_html": "",
    "text": "The Model Context Protocol (MCP) is an open standard for connecting AI agents to external systems. Connecting agents to tools and data traditionally requires a custom integration for each pairing, creating fragmentation and duplicated effort that makes it difficult to scale truly connected systems. MCP provides a universal protocol-developers implement MCP once in their agent and it unlocks an entire ecosystem of integrations.\n\nSince launching MCP in November 2024, adoption has been rapid: the community has built thousands of MCP servers , SDKs are available for all major programming languages, and the industry has adopted MCP as the de-facto standard for connecting agents to tools and data.\n\nToday developers routinely build agents with access to hundreds or thousands of tools across dozens of MCP servers. However, as the number of connected tools grows, loading all tool definitions upfront and passing intermediate results through the context window slows down agents and increases costs.\n\nIn this blog we'll explore how code execution can enable agents to interact with MCP servers more efficiently, handling more tools while using fewer tokens.\n\nExcessive token consumption from tools makes agents less efficient\n\nAs MCP usage scales, there are two common patterns that can increase agent cost and latency:\n\n- Tool definitions overload the context window;\n\n- Intermediate tool results consume additional tokens.\n\n1. Tool definitions overload the context window\n\nMost MCP clients load all tool definitions upfront directly into context, exposing them to the model using a direct tool-calling syntax. These tool definitions might look like:\n\n```\ngdrive.getDocument\n     Description: Retrieves a document from Google Drive\n     Parameters:\n                documentId (required, string): The ID of the document to retrieve\n                fields (optional, string): Specific fields to return\n     Returns: Document object with title, body content, metadata, permissions, etc.\n```\n\n```\nsalesforce.updateRecord\n    Description: Updates a record in Salesforce\n    Parameters:\n               objectType (required, string): Type of Salesforce object (Lead, Contact,      Account, etc.)\n               recordId (required, string): The ID of the record to update\n               data (required, object): Fields to update with their new values\n     Returns: Updated record object with confirmation\n```\n\nTool descriptions occupy more context window space, increasing response time and costs. In cases where agents are connected to thousands of tools, they'll need to process hundreds of thousands of tokens before reading a request.\n\n2. Intermediate tool results consume additional tokens\n\nMost MCP clients allow models to directly call MCP tools. For example, you might ask your agent: \"Download my meeting transcript from Google Drive and attach it to the Salesforce lead.\"\n\nThe model will make calls like:\n\n```\nTOOL CALL: gdrive.getDocument(documentId: \"abc123\")\n        → returns \"Discussed Q4 goals...\\n[full transcript text]\"\n           (loaded into model context)\n\nTOOL CALL: salesforce.updateRecord(\n\t\t\tobjectType: \"SalesMeeting\",\n\t\t\trecordId: \"00Q5f000001abcXYZ\",\n  \t\t\tdata: { \"Notes\": \"Discussed Q4 goals...\\n[full transcript text written out]\" }\n\t\t)\n\t\t(model needs to write entire transcript into context again)\n```\n\nEvery intermediate result must pass through the model. In this example, the full call transcript flows through twice. For a 2-hour sales meeting, that could mean processing an additional 50,000 tokens. Even larger documents may exceed context window limits, breaking the workflow.\n\nWith large documents or complex data structures, models may be more likely to make mistakes when copying data between tool calls.\n\n[[IMAGE_1|The MCP client loads tool definitions into the model's context window and orchestrates a message loop where each tool call and result passes through the model between operations.]]\n\nCode execution with MCP improves context efficiency\n\nWith code execution environments becoming more common for agents, a solution is to present MCP servers as code APIs rather than direct tool calls. The agent can then write code to interact with MCP servers. This approach addresses both challenges: agents can load only the tools they need and process data in the execution environment before passing results back to the model.\n\nThere are a number of ways to do this. One approach is to generate a file tree of all available tools from connected MCP servers. Here's an implementation using TypeScript:\n\n```\nservers\n├── google-drive\n│   ├── getDocument.ts\n│   ├── ... (other tools)\n│   └── index.ts\n├── salesforce\n│   ├── updateRecord.ts\n│   ├── ... (other tools)\n│   └── index.ts\n└── ... (other servers)\n```\n\nThen each tool corresponds to a file, something like:\n\n```\n// ./servers/google-drive/getDocument.ts\nimport { callMCPTool } from \"../../../client.js\";\n\ninterface GetDocumentInput {\n  documentId: string;\n}\n\ninterface GetDocumentResponse {\n  content: string;\n}\n\n/* Read a document from Google Drive */\nexport async function getDocument(input: GetDocumentInput): Promise<GetDocumentResponse> {\n  return callMCPTool<GetDocumentResponse>('google_drive__get_document', input);\n}\n```\n\nOur Google Drive to Salesforce example above becomes the code:\n\n```\n// Read transcript from Google Docs and add to Salesforce prospect\nimport * as gdrive from './servers/google-drive';\nimport * as salesforce from './servers/salesforce';\n\nconst transcript = (await gdrive.getDocument({ documentId: 'abc123' })).content;\nawait salesforce.updateRecord({\n  objectType: 'SalesMeeting',\n  recordId: '00Q5f000001abcXYZ',\n  data: { Notes: transcript }\n});\n```\n\nThe agent discovers tools by exploring the filesystem: listing the ./servers/ directory to find available servers (like google-drive and salesforce ), then reading the specific tool files it needs (like getDocument.ts and updateRecord.ts ) to understand each tool's interface. This lets the agent load only the definitions it needs for the current task. This reduces the token usage from 150,000 tokens to 2,000 tokens-a time and cost saving of 98.7% .\n\nCloudflare published similar findings , referring to code execution with MCP as \"Code Mode.\" The core insight is the same: LLMs are adept at writing code and developers should take advantage of this strength to build agents that interact with MCP servers more efficiently.\n\nBenefits of code execution with MCP\n\nCode execution with MCP enables agents to use context more efficiently by loading tools on demand, filtering data before it reaches the model, and executing complex logic in a single step. There are also security and state management benefits to using this approach.\n\nProgressive disclosure\n\nModels are great at navigating filesystems. Presenting tools as code on a filesystem allows models to read tool definitions on-demand, rather than reading them all up-front.\n\nAlternatively, a search_tools tool can be added to the server to find relevant definitions. For example, when working with the hypothetical Salesforce server used above, the agent searches for \"salesforce\" and loads only those tools that it needs for the current task. Including a detail level parameter in the search_tools tool that allows the agent to select the level of detail required (such as name only, name and description, or the full definition with schemas) also helps the agent conserve context and find tools efficiently.\n\nContext efficient tool results\n\nWhen working with large datasets, agents can filter and transform results in code before returning them. Consider fetching a 10,000-row spreadsheet:\n\n```\n// Without code execution - all rows flow through context\nTOOL CALL: gdrive.getSheet(sheetId: 'abc123')\n        → returns 10,000 rows in context to filter manually\n\n// With code execution - filter in the execution environment\nconst allRows = await gdrive.getSheet({ sheetId: 'abc123' });\nconst pendingOrders = allRows.filter(row => \n  row[\"Status\"] === 'pending'\n);\nconsole.log(`Found ${pendingOrders.length} pending orders`);\nconsole.log(pendingOrders.slice(0, 5)); // Only log first 5 for review\n```\n\nThe agent sees five rows instead of 10,000. Similar patterns work for aggregations, joins across multiple data sources, or extracting specific fields-all without bloating the context window.\n\nMore powerful and context-efficient control flow\n\nLoops, conditionals, and error handling can be done with familiar code patterns rather than chaining individual tool calls. For example, if you need a deployment notification in Slack, the agent can write:\n\n```\nlet found = false;\nwhile (!found) {\n  const messages = await slack.getChannelHistory({ channel: 'C123456' });\n  found = messages.some(m => m.text.includes('deployment complete'));\n  if (!found) await new Promise(r => setTimeout(r, 5000));\n}\nconsole.log('Deployment notification received');\n```\n\nThis approach is more efficient than alternating between MCP tool calls and sleep commands through the agent loop.\n\nAdditionally, being able to write out a conditional tree that gets executed also saves on \"time to first token\" latency: rather than having to wait for a model to evaluate an if-statement, the agent can let the code execution environment do this.\n\nPrivacy-preserving operations\n\nWhen agents use code execution with MCP, intermediate results stay in the execution environment by default. This way, the agent only sees what you explicitly log or return, meaning data you don't wish to share with the model can flow through your workflow without ever entering the model's context.\n\nFor even more sensitive workloads, the agent harness can tokenize sensitive data automatically. For example, imagine you need to import customer contact details from a spreadsheet into Salesforce. The agent writes:\n\n```\nconst sheet = await gdrive.getSheet({ sheetId: 'abc123' });\nfor (const row of sheet.rows) {\n  await salesforce.updateRecord({\n    objectType: 'Lead',\n    recordId: row.salesforceId,\n    data: { \n      Email: row.email,\n      Phone: row.phone,\n      Name: row.name\n    }\n  });\n}\nconsole.log(`Updated ${sheet.rows.length} leads`);\n```\n\nThe MCP client intercepts the data and tokenizes PII before it reaches the model:\n\n```\n// What the agent would see, if it logged the sheet.rows:\n[\n  { salesforceId: '00Q...', email: '[EMAIL_1]', phone: '[PHONE_1]', name: '[NAME_1]' },\n  { salesforceId: '00Q...', email: '[EMAIL_2]', phone: '[PHONE_2]', name: '[NAME_2]' },\n  ...\n]\n```\n\nThen, when the data is shared in another MCP tool call, it is untokenized via a lookup in the MCP client. The real email addresses, phone numbers, and names flow from Google Sheets to Salesforce, but never through the model. This prevents the agent from accidentally logging or processing sensitive data. You can also use this to define deterministic security rules, choosing where data can flow to and from.\n\nState persistence and skills\n\nCode execution with filesystem access allows agents to maintain state across operations. Agents can write intermediate results to files, enabling them to resume work and track progress:\n\n```\nconst leads = await salesforce.query({ \n  query: 'SELECT Id, Email FROM Lead LIMIT 1000' \n});\nconst csvData = leads.map(l => `${l.Id},${l.Email}`).join('\\n');\nawait fs.writeFile('./workspace/leads.csv', csvData);\n\n// Later execution picks up where it left off\nconst saved = await fs.readFile('./workspace/leads.csv', 'utf-8');\n```\n\nAgents can also persist their own code as reusable functions. Once an agent develops working code for a task, it can save that implementation for future use:\n\n```\n// In ./skills/save-sheet-as-csv.ts\nimport * as gdrive from './servers/google-drive';\nexport async function saveSheetAsCsv(sheetId: string) {\n  const data = await gdrive.getSheet({ sheetId });\n  const csv = data.map(row => row.join(',')).join('\\n');\n  await fs.writeFile(`./workspace/sheet-${sheetId}.csv`, csv);\n  return `./workspace/sheet-${sheetId}.csv`;\n}\n\n// Later, in any agent execution:\nimport { saveSheetAsCsv } from './skills/save-sheet-as-csv';\nconst csvPath = await saveSheetAsCsv('abc123');\n```\n\nThis ties in closely to the concept of Skills , folders of reusable instructions, scripts, and resources for models to improve performance on specialized tasks. Adding a SKILL.md file to these saved functions creates a structured skill that models can reference and use. Over time, this allows your agent to build a toolbox of higher-level capabilities, evolving the scaffolding that it needs to work most effectively.\n\nNote that code execution introduces its own complexity. Running agent-generated code requires a secure execution environment with appropriate sandboxing , resource limits, and monitoring. These infrastructure requirements add operational overhead and security considerations that direct tool calls avoid. The benefits of code execution-reduced token costs, lower latency, and improved tool composition-should be weighed against these implementation costs.\n\nSummary\n\nMCP provides a foundational protocol for agents to connect to many tools and systems. However, once too many servers are connected, tool definitions and results can consume excessive tokens, reducing agent efficiency.\n\nAlthough many of the problems here feel novel-context management, tool composition, state persistence-they have known solutions from software engineering. Code execution applies these established patterns to agents, letting them use familiar programming constructs to interact with MCP servers more efficiently. If you implement this approach, we encourage you to share your findings with the MCP community .\n\nAcknowledgments\n\nThis article was written by Adam Jones and Conor Kelly. Thanks to Jeremy Fox, Jerome Swannack, Stuart Ritchie, Molly Vorwerck, Matt Samuels, and Maggie Vo for feedback on drafts of this post.",
    "images": [
      "https://www-cdn.anthropic.com/images/4zrzovbb/website/42f40f6fae9ec2d7cf2e5a98908a16d0216b91be-1000x1000.svg",
      "https://www-cdn.anthropic.com/images/4zrzovbb/website/9ecf165020005c09a22a9472cee6309555485619-1920x1080.png"
    ]
  },
  "translations": {
    "es": {
      "title": "Ejecución de código con MCP: creación de agentes más eficientes",
      "content": "El Model Context Protocol (MCP) es un estándar abierto para conectar agentes de IA con sistemas externos. Conectar agentes a herramientas y datos tradicionalmente exige una integración a medida para cada combinación, lo que fragmenta y duplica esfuerzos y dificulta escalar sistemas realmente conectados. MCP ofrece un protocolo universal: los desarrolladores implementan MCP una vez en su agente y desbloquean todo un ecosistema de integraciones.\n\nDesde el lanzamiento de MCP en noviembre de 2024, la adopción ha sido rápida: la comunidad ha construido miles de servidores MCP, hay SDK disponibles para todos los lenguajes principales y la industria lo usa como estándar de facto para conectar agentes con herramientas y datos.\n\nHoy los desarrolladores crean agentes con acceso a cientos o miles de herramientas a través de docenas de servidores MCP. Sin embargo, a medida que crece el número de herramientas conectadas, cargar todas las definiciones por adelantado y pasar resultados intermedios por la ventana de contexto ralentiza a los agentes y aumenta los costos.\n\nEn este artículo exploramos cómo la ejecución de código permite que los agentes interactúen con servidores MCP de forma más eficiente, manejando más herramientas con menos tokens.\n\nEl consumo excesivo de tokens de las herramientas hace que los agentes sean menos eficientes\n\nA medida que escala MCP, aparecen dos patrones que aumentan costo y latencia:\n\n- Las definiciones de herramientas saturan la ventana de contexto;\n\n- Los resultados intermedios consumen tokens adicionales.\n\n1. Las definiciones de herramientas saturan la ventana de contexto\n\nLa mayoría de los clientes MCP cargan todas las definiciones de herramientas directamente en el contexto, exponiéndolas al modelo con sintaxis de llamada directa. Esas definiciones pueden verse así:\n\n```\ngdrive.getDocument\n     Description: Retrieves a document from Google Drive\n     Parameters:\n                documentId (required, string): The ID of the document to retrieve\n                fields (optional, string): Specific fields to return\n     Returns: Document object with title, body content, metadata, permissions, etc.\n```\n\n```\nsalesforce.updateRecord\n    Description: Updates a record in Salesforce\n    Parameters:\n               objectType (required, string): Type of Salesforce object (Lead, Contact,      Account, etc.)\n               recordId (required, string): The ID of the record to update\n               data (required, object): Fields to update with their new values\n     Returns: Updated record object with confirmation\n```\n\nLas descripciones de herramientas ocupan más espacio en la ventana de contexto, aumentando tiempo de respuesta y costos. En casos donde los agentes están conectados a miles de herramientas, deben procesar cientos de miles de tokens antes incluso de leer una petición.\n\n2. Los resultados intermedios consumen tokens adicionales\n\nLa mayoría de los clientes MCP permiten que los modelos llamen herramientas directamente. Por ejemplo, podrías pedirle a tu agente: \"Descarga la transcripción de mi reunión desde Google Drive y adjúntala al lead de Salesforce\".\n\nEl modelo hará llamadas como:\n\n```\nTOOL CALL: gdrive.getDocument(documentId: \"abc123\")\n        → returns \"Discussed Q4 goals...\n[full transcript text]\"\n           (loaded into model context)\n\nTOOL CALL: salesforce.updateRecord(\n\t\t\tobjectType: \"SalesMeeting\",\n\t\t\trecordId: \"00Q5f000001abcXYZ\",\n  \t\t\tdata: { \"Notes\": \"Discussed Q4 goals...\n[full transcript text written out]\" }\n\t\t)\n\t\t(model needs to write entire transcript into context again)\n```\n\nCada resultado intermedio debe pasar por el modelo. En este ejemplo, la transcripción completa circula dos veces. Para una reunión de dos horas podrían ser 50,000 tokens adicionales. Documentos aún más grandes pueden superar los límites de la ventana de contexto y romper el flujo.\n\nCon documentos grandes o estructuras de datos complejas, es más probable que el modelo cometa errores al copiar datos entre llamadas de herramienta.\n\n[[IMAGE_1|El cliente MCP carga las definiciones de herramientas en la ventana de contexto del modelo y orquesta un ciclo de mensajes donde cada llamada y resultado pasa por el modelo entre operaciones.]]\n\nLa ejecución de código con MCP mejora la eficiencia del contexto\n\nAhora que los entornos de ejecución de código son comunes para agentes, una solución es presentar los servidores MCP como APIs de código en lugar de llamadas directas. El agente escribe código para interactuar con los servidores MCP. Este enfoque resuelve ambos problemas: el agente carga solo las herramientas que necesita y procesa los datos en el entorno de ejecución antes de devolver resultados al modelo.\n\nHay varias maneras de hacerlo. Una es generar un árbol de archivos con todas las herramientas disponibles de los servidores MCP conectados. Aquí hay una implementación en TypeScript:\n\n```\nservers\n├── google-drive\n│   ├── getDocument.ts\n│   ├── ... (other tools)\n│   └── index.ts\n├── salesforce\n│   ├── updateRecord.ts\n│   ├── ... (other tools)\n│   └── index.ts\n└── ... (other servers)\n```\n\nLuego cada herramienta corresponde a un archivo, algo como:\n\n```\n// ./servers/google-drive/getDocument.ts\nimport { callMCPTool } from \"../../../client.js\";\n\ninterface GetDocumentInput {\n  documentId: string;\n}\n\ninterface GetDocumentResponse {\n  content: string;\n}\n\n/* Read a document from Google Drive */\nexport async function getDocument(input: GetDocumentInput): Promise<GetDocumentResponse> {\n  return callMCPTool<GetDocumentResponse>('google_drive__get_document', input);\n}\n```\n\nNuestro ejemplo de Google Drive a Salesforce se convierte en este código:\n\n```\n// Read transcript from Google Docs and add to Salesforce prospect\nimport * as gdrive from './servers/google-drive';\nimport * as salesforce from './servers/salesforce';\n\nconst transcript = (await gdrive.getDocument({ documentId: 'abc123' })).content;\nawait salesforce.updateRecord({\n  objectType: 'SalesMeeting',\n  recordId: '00Q5f000001abcXYZ',\n  data: { Notes: transcript }\n});\n```\n\nEl agente descubre las herramientas explorando el sistema de archivos: lista el directorio ./servers/ para encontrar servidores disponibles (como google-drive y salesforce) y luego lee los archivos de herramientas que necesita (como getDocument.ts y updateRecord.ts) para entender cada interfaz. Así puede cargar solo las definiciones necesarias para la tarea actual. Esto reduce el uso de tokens de 150,000 a 2,000, un ahorro de 98.7%.\n\nCloudflare publicó hallazgos similares y se refiere a la ejecución de código con MCP como \"Code Mode\". La idea central es la misma: los LLM son buenos escribiendo código y los desarrolladores deberían aprovechar esta fortaleza para que los agentes interactúen con servidores MCP de manera más eficiente.\n\nBeneficios de la ejecución de código con MCP\n\nLa ejecución de código con MCP permite que los agentes usen el contexto con más eficiencia cargando herramientas bajo demanda, filtrando datos antes de que lleguen al modelo y ejecutando lógica compleja en un solo paso. También hay beneficios de seguridad y manejo de estado.\n\nDivulgación progresiva\n\nLos modelos son buenos navegando sistemas de archivos. Presentar herramientas como código en un sistema de archivos permite que el modelo lea definiciones bajo demanda en lugar de leerlas todas al inicio.\n\nAlternativamente, se puede añadir una herramienta search_tools al servidor para encontrar definiciones relevantes. Por ejemplo, al trabajar con el servidor hipotético de Salesforce usado arriba, el agente busca \"salesforce\" y carga solo las herramientas que necesita. Incluir un parámetro detail level en search_tools que permita elegir el nivel de detalle requerido (solo nombre, nombre + descripción o definición completa con esquemas) ayuda a conservar contexto y encontrar herramientas con eficiencia.\n\nResultados de herramientas eficientes en contexto\n\nCuando se trabaja con conjuntos de datos grandes, los agentes pueden filtrar y transformar resultados en código antes de devolverlos. Considera obtener una hoja de cálculo de 10,000 filas:\n\n```\n// Without code execution - all rows flow through context\nTOOL CALL: gdrive.getSheet(sheetId: 'abc123')\n        → returns 10,000 rows in context to filter manually\n\n// With code execution - filter in the execution environment\nconst allRows = await gdrive.getSheet({ sheetId: 'abc123' });\nconst pendingOrders = allRows.filter(row => \n  row[\"Status\"] === 'pending'\n);\nconsole.log(`Found ${pendingOrders.length} pending orders`);\nconsole.log(pendingOrders.slice(0, 5)); // Only log first 5 for review\n```\n\nEl agente ve cinco filas en lugar de 10,000. Patrones similares funcionan para agregaciones, joins entre varias fuentes o extracción de campos específicos, todo sin inflar la ventana de contexto.\n\nFlujo de control más potente y eficiente\n\nLos bucles, condicionales y manejo de errores se pueden hacer con patrones de código familiares en vez de encadenar llamadas individuales. Por ejemplo, si necesitas una notificación de despliegue en Slack:\n\n```\nlet found = false;\nwhile (!found) {\n  const messages = await slack.getChannelHistory({ channel: 'C123456' });\n  found = messages.some(m => m.text.includes('deployment complete'));\n  if (!found) await new Promise(r => setTimeout(r, 5000));\n}\nconsole.log('Deployment notification received');\n```\n\nEste enfoque es más eficiente que alternar llamadas de herramienta y sleep a través del loop del agente.\n\nTambién reduce la latencia de \"time to first token\": en vez de esperar a que el modelo evalúe un if, el entorno de ejecución lo hace.\n\nOperaciones que preservan la privacidad\n\nCon ejecución de código en MCP, los resultados intermedios permanecen en el entorno de ejecución por defecto. Así el agente solo ve lo que registras o devuelves explícitamente, lo que permite que datos sensibles fluyan sin entrar al contexto del modelo.\n\nPara cargas aún más sensibles, el arnés del agente puede tokenizar datos automáticamente. Por ejemplo, imaginemos importar contactos de clientes de una hoja de cálculo a Salesforce. El agente escribe:\n\n```\nconst sheet = await gdrive.getSheet({ sheetId: 'abc123' });\nfor (const row of sheet.rows) {\n  await salesforce.updateRecord({\n    objectType: 'Lead',\n    recordId: row.salesforceId,\n    data: { \n      Email: row.email,\n      Phone: row.phone,\n      Name: row.name\n    }\n  });\n}\nconsole.log(`Updated ${sheet.rows.length} leads`);\n```\n\nEl cliente MCP intercepta los datos y tokeniza la PII antes de que llegue al modelo:\n\n```\n// What the agent would see, if it logged the sheet.rows:\n[\n  { salesforceId: '00Q...', email: '[EMAIL_1]', phone: '[PHONE_1]', name: '[NAME_1]' },\n  { salesforceId: '00Q...', email: '[EMAIL_2]', phone: '[PHONE_2]', name: '[NAME_2]' },\n  ...\n]\n```\n\nLuego, cuando los datos se comparten en otra llamada MCP, se destokenizan mediante una búsqueda en el cliente MCP. Los correos electrónicos, teléfonos y nombres reales fluyen de Google Sheets a Salesforce, pero nunca pasan por el modelo. Esto evita que el agente registre o procese datos sensibles y permite definir reglas de seguridad determinísticas sobre cómo pueden fluir los datos.\n\nPersistencia de estado y skills\n\nLa ejecución de código con acceso a sistema de archivos permite que los agentes mantengan estado entre operaciones. Pueden escribir resultados intermedios en archivos, reanudar trabajo y seguir el progreso:\n\n```\nconst leads = await salesforce.query({ \n  query: 'SELECT Id, Email FROM Lead LIMIT 1000' \n});\nconst csvData = leads.map(l => `${l.Id},${l.Email}`).join('\n');\nawait fs.writeFile('./workspace/leads.csv', csvData);\n\n// Later execution picks up where it left off\nconst saved = await fs.readFile('./workspace/leads.csv', 'utf-8');\n```\n\nLos agentes también pueden guardar su propio código como funciones reutilizables. Una vez que un agente desarrolla código funcional para una tarea, puede guardarlo para futuras ejecuciones:\n\n```\n// In ./skills/save-sheet-as-csv.ts\nimport * as gdrive from './servers/google-drive';\nexport async function saveSheetAsCsv(sheetId: string) {\n  const data = await gdrive.getSheet({ sheetId });\n  const csv = data.map(row => row.join(',')).join('\n');\n  await fs.writeFile(`./workspace/sheet-${sheetId}.csv`, csv);\n  return `./workspace/sheet-${sheetId}.csv`;\n}\n\n// Later, in any agent execution:\nimport { saveSheetAsCsv } from './skills/save-sheet-as-csv';\nconst csvPath = await saveSheetAsCsv('abc123');\n```\n\nEsto se relaciona con el concepto de Skills: carpetas con instrucciones, scripts y recursos reutilizables para que los modelos mejoren en tareas especializadas. Añadir un archivo SKILL.md a esas funciones guardadas crea una skill estructurada que los modelos pueden consultar y usar. Con el tiempo, tu agente construye un conjunto de capacidades reutilizables, evolucionando el andamiaje que necesita para trabajar con eficacia.\n\nTen en cuenta que la ejecución de código introduce su propia complejidad. Ejecutar código generado por el agente requiere un entorno seguro con sandboxing, límites de recursos y monitoreo. Estos requisitos añaden sobrecarga operativa y consideraciones de seguridad que las llamadas directas evitan. Los beneficios de la ejecución de código (menos tokens, menor latencia y mejor composición de herramientas) deben sopesarse frente a los costos de implementación.\n\nResumen\n\nMCP ofrece un protocolo base para que los agentes se conecten a muchas herramientas y sistemas. Sin embargo, cuando se conectan demasiados servidores, las definiciones y resultados pueden consumir tokens en exceso y reducir la eficiencia del agente.\n\nAunque muchos de estos problemas parezcan novedosos (gestión de contexto, composición de herramientas, persistencia de estado), tienen soluciones conocidas en ingeniería de software. La ejecución de código aplica esos patrones a los agentes, permitiéndoles usar construcciones de programación familiares para interactuar con servidores MCP de forma más eficiente. Si implementas este enfoque, te animamos a compartir tus hallazgos con la comunidad MCP.\n\nAgradecimientos\n\nEste artículo fue escrito por Adam Jones y Conor Kelly. Gracias a Jeremy Fox, Jerome Swannack, Stuart Ritchie, Molly Vorwerck, Matt Samuels y Maggie Vo por los comentarios sobre los borradores.",
      "edited": false
    },
    "ukr": {
      "title": "Виконання коду з MCP: створення ефективніших агентів",
      "content": "Model Context Protocol (MCP) — це відкритий стандарт для підключення агентів ШІ до зовнішніх систем. Традиційно з'єднати агент із інструментами й даними означає писати окрему інтеграцію для кожної пари, що веде до фрагментації й дублювання зусиль та ускладнює масштабування справді під'єднаних систем. MCP дає універсальний протокол: розробники впроваджують MCP один раз у агенті й отримують доступ до всього екосистеми інтеграцій.\n\nВід моменту запуску MCP у листопаді 2024 року його швидко прийняли: спільнота створила тисячі серверів MCP, є SDK для всіх основних мов, а індустрія використовує MCP як де-факто стандарт для підключення агентів до інструментів і даних.\n\nСьогодні розробники будують агентів із доступом до сотень чи тисяч інструментів через десятки серверів MCP. Але зі зростанням кількості підключених інструментів завантаження всіх визначень наперед і передавання проміжних результатів через вікно контексту сповільнює агентів і збільшує витрати.\n\nУ цій статті ми показуємо, як виконання коду допомагає агентам ефективніше взаємодіяти з серверами MCP, працюючи з більшою кількістю інструментів і використовуючи менше токенів.\n\nНадмірне споживання токенів інструментами знижує ефективність агентів\n\nУ міру масштабування MCP з'являються два поширені патерни, що підвищують вартість і затримки:\n\n- Визначення інструментів перевантажують вікно контексту;\n\n- Проміжні результати інструментів споживають додаткові токени.\n\n1. Визначення інструментів перевантажують контекст\n\nБільшість клієнтів MCP завантажують усі визначення інструментів безпосередньо в контекст, показуючи їх моделі через прямий синтаксис викликів. Такі визначення можуть виглядати так:\n\n```\ngdrive.getDocument\n     Description: Retrieves a document from Google Drive\n     Parameters:\n                documentId (required, string): The ID of the document to retrieve\n                fields (optional, string): Specific fields to return\n     Returns: Document object with title, body content, metadata, permissions, etc.\n```\n\n```\nsalesforce.updateRecord\n    Description: Updates a record in Salesforce\n    Parameters:\n               objectType (required, string): Type of Salesforce object (Lead, Contact,      Account, etc.)\n               recordId (required, string): The ID of the record to update\n               data (required, object): Fields to update with their new values\n     Returns: Updated record object with confirmation\n```\n\nОпис інструментів займає дедалі більше місця у вікні контексту, збільшуючи час відповіді й витрати. Якщо агент підключений до тисяч інструментів, йому доведеться опрацювати сотні тисяч токенів ще до читання запиту.\n\n2. Проміжні результати споживають токени\n\nБільшість клієнтів MCP дозволяють моделям напряму викликати інструменти. Наприклад, ви можете попросити агента: «Завантаж транскрипт зустрічі з Google Drive і прикріпи його до ліда в Salesforce».\n\nМодель робитиме виклики на кшталт:\n\n```\nTOOL CALL: gdrive.getDocument(documentId: \"abc123\")\n        → returns \"Discussed Q4 goals...\n[full transcript text]\"\n           (loaded into model context)\n\nTOOL CALL: salesforce.updateRecord(\n\t\t\tobjectType: \"SalesMeeting\",\n\t\t\trecordId: \"00Q5f000001abcXYZ\",\n  \t\t\tdata: { \"Notes\": \"Discussed Q4 goals...\n[full transcript text written out]\" }\n\t\t)\n\t\t(model needs to write entire transcript into context again)\n```\n\nКожен проміжний результат проходить через модель. У цьому прикладі повний транскрипт двічі потрапляє в контекст. Для двогодинної зустрічі це може означати ще 50 000 токенів. Ще більші документи можуть перевищити ліміт контексту й зламати процес.\n\nЗ великими документами чи складними структурами даних імовірність помилок при копіюванні даних між викликами зростає.\n\n[[IMAGE_1|Клієнт MCP завантажує визначення інструментів у вікно контексту моделі й координує цикл повідомлень, у якому кожен виклик інструменту та результат проходить через модель між операціями.]]\n\nВиконання коду з MCP підвищує ефективність контексту\n\nОскільки середовища виконання коду стають звичними для агентів, рішенням є подати сервери MCP як кодові API замість прямих викликів. Агент пише код, щоб взаємодіяти з серверами MCP. Такий підхід розв'язує обидві проблеми: агент завантажує лише потрібні інструменти й обробляє дані у середовищі виконання, перш ніж повернути результат моделі.\n\nІснує кілька способів зробити це. Один із них — згенерувати дерево файлів з усіма доступними інструментами підключених серверів MCP. Ось реалізація на TypeScript:\n\n```\nservers\n├── google-drive\n│   ├── getDocument.ts\n│   ├── ... (other tools)\n│   └── index.ts\n├── salesforce\n│   ├── updateRecord.ts\n│   ├── ... (other tools)\n│   └── index.ts\n└── ... (other servers)\n```\n\nДалі кожному інструменту відповідає файл, приблизно такий:\n\n```\n// ./servers/google-drive/getDocument.ts\nimport { callMCPTool } from \"../../../client.js\";\n\ninterface GetDocumentInput {\n  documentId: string;\n}\n\ninterface GetDocumentResponse {\n  content: string;\n}\n\n/* Read a document from Google Drive */\nexport async function getDocument(input: GetDocumentInput): Promise<GetDocumentResponse> {\n  return callMCPTool<GetDocumentResponse>('google_drive__get_document', input);\n}\n```\n\nНаш приклад із Google Drive до Salesforce перетворюється на цей код:\n\n```\n// Read transcript from Google Docs and add to Salesforce prospect\nimport * as gdrive from './servers/google-drive';\nimport * as salesforce from './servers/salesforce';\n\nconst transcript = (await gdrive.getDocument({ documentId: 'abc123' })).content;\nawait salesforce.updateRecord({\n  objectType: 'SalesMeeting',\n  recordId: '00Q5f000001abcXYZ',\n  data: { Notes: transcript }\n});\n```\n\nАгент відкриває інструменти, досліджуючи файлову систему: перелічує каталог ./servers/ щоб знайти доступні сервери (google-drive, salesforce), а потім читає потрібні файли інструментів (getDocument.ts, updateRecord.ts), щоб зрозуміти їхній інтерфейс. Це дозволяє завантажувати лише потрібні визначення. Використання токенів скорочується з 150 000 до 2 000 — економія 98.7%.\n\nCloudflare опублікувала схожі висновки, називаючи виконання коду з MCP \"Code Mode\". Ідея та сама: LLM добре пишуть код, і розробникам варто використати цю сильну сторону, щоб агенти ефективніше працювали з серверами MCP.\n\nПереваги виконання коду з MCP\n\nВиконання коду з MCP дає змогу агентам економніше використовувати контекст: завантажувати інструменти за потребою, фільтрувати дані перед тим, як вони потраплять у модель, і виконувати складну логіку одним кроком. Також є переваги для безпеки та керування станом.\n\nПоступове розкриття\n\nМоделі добре орієнтуються у файлових системах. Подання інструментів як коду у файловій системі дозволяє моделі читати визначення за запитом, а не всі одразу.\n\nАльтернативно можна додати на сервер інструмент search_tools для пошуку релевантних визначень. Наприклад, у гіпотетичному сервері Salesforce агент шукає \"salesforce\" і завантажує лише потрібні інструменти. Додавання параметра detail level у search_tools (лише назва, назва + опис або повне визначення зі схемами) допомагає економити контекст і знаходити інструменти швидко.\n\nЕфективні результати інструментів у контексті\n\nПри роботі з великими даними агенти можуть відфільтровувати й трансформувати результати в коді перед поверненням. Приклад із таблицею на 10 000 рядків:\n\n```\n// Without code execution - all rows flow through context\nTOOL CALL: gdrive.getSheet(sheetId: 'abc123')\n        → returns 10,000 rows in context to filter manually\n\n// With code execution - filter in the execution environment\nconst allRows = await gdrive.getSheet({ sheetId: 'abc123' });\nconst pendingOrders = allRows.filter(row => \n  row[\"Status\"] === 'pending'\n);\nconsole.log(`Found ${pendingOrders.length} pending orders`);\nconsole.log(pendingOrders.slice(0, 5)); // Only log first 5 for review\n```\n\nАгент бачить п'ять рядків замість 10 000. Подібні патерни працюють для агрегацій, з'єднань між джерелами чи вибірки окремих полів без роздування контексту.\n\nПотужніший і контекстно-ефективний контроль потоку\n\nЦикли, умови й обробку помилок можна робити звичними кодовими патернами, а не ланцюжити окремі виклики. Наприклад, якщо потрібне сповіщення про деплой у Slack:\n\n```\nlet found = false;\nwhile (!found) {\n  const messages = await slack.getChannelHistory({ channel: 'C123456' });\n  found = messages.some(m => m.text.includes('deployment complete'));\n  if (!found) await new Promise(r => setTimeout(r, 5000));\n}\nconsole.log('Deployment notification received');\n```\n\nТакий підхід ефективніший, ніж чергування викликів інструменту та sleep у циклі агента.\n\nВін також зменшує затримку time to first token: замість того щоб чекати, поки модель оцінить if, це робить середовище виконання.\n\nОперації зберігання конфіденційності\n\nКоли агенти використовують виконання коду з MCP, проміжні результати за замовчуванням лишаються у середовищі виконання. Агент бачить лише те, що ви явно логувати чи повертаєте, тож дані, які ви не хочете ділити з моделлю, можуть пройти через workflow без потрапляння в контекст.\n\nДля ще чутливіших навантажень клієнт агента може автоматично токенізувати дані. Наприклад, потрібно імпортувати контактні дані клієнтів з таблиці в Salesforce. Агент пише:\n\n```\nconst sheet = await gdrive.getSheet({ sheetId: 'abc123' });\nfor (const row of sheet.rows) {\n  await salesforce.updateRecord({\n    objectType: 'Lead',\n    recordId: row.salesforceId,\n    data: { \n      Email: row.email,\n      Phone: row.phone,\n      Name: row.name\n    }\n  });\n}\nconsole.log(`Updated ${sheet.rows.length} leads`);\n```\n\nКлієнт MCP перехоплює дані й токенізує PII, перш ніж вони потраплять у модель:\n\n```\n// What the agent would see, if it logged the sheet.rows:\n[\n  { salesforceId: '00Q...', email: '[EMAIL_1]', phone: '[PHONE_1]', name: '[NAME_1]' },\n  { salesforceId: '00Q...', email: '[EMAIL_2]', phone: '[PHONE_2]', name: '[NAME_2]' },\n  ...\n]\n```\n\nКоли дані передаються в іншому виклику MCP, вони детокенізуються через lookup у клієнті. Реальні email, телефони й імена йдуть із Google Sheets у Salesforce, але не проходять через модель, тож агент не може випадково залогувати чи обробити їх. Ви також можете задати детерміновані правила безпеки для контролю маршрутів даних.\n\nЗбереження стану та skills\n\nВиконання коду з доступом до файлової системи дозволяє агентам утримувати стан між операціями. Вони можуть записувати проміжні результати у файли, відновлювати роботу й відстежувати прогрес:\n\n```\nconst leads = await salesforce.query({ \n  query: 'SELECT Id, Email FROM Lead LIMIT 1000' \n});\nconst csvData = leads.map(l => `${l.Id},${l.Email}`).join('\n');\nawait fs.writeFile('./workspace/leads.csv', csvData);\n\n// Later execution picks up where it left off\nconst saved = await fs.readFile('./workspace/leads.csv', 'utf-8');\n```\n\nАгенти також можуть зберігати свій код як багаторазові функції. Коли агент написав робочий код для задачі, він може зберегти його для наступних запусків:\n\n```\n// In ./skills/save-sheet-as-csv.ts\nimport * as gdrive from './servers/google-drive';\nexport async function saveSheetAsCsv(sheetId: string) {\n  const data = await gdrive.getSheet({ sheetId });\n  const csv = data.map(row => row.join(',')).join('\n');\n  await fs.writeFile(`./workspace/sheet-${sheetId}.csv`, csv);\n  return `./workspace/sheet-${sheetId}.csv`;\n}\n\n// Later, in any agent execution:\nimport { saveSheetAsCsv } from './skills/save-sheet-as-csv';\nconst csvPath = await saveSheetAsCsv('abc123');\n```\n\nЦе тісно пов'язано з концепцією Skills — тек з інструкціями, скриптами й ресурсами, що роблять моделі кращими у спеціалізованих задачах. Додавши файл SKILL.md до збережених функцій, ви створюєте структуровану skill, яку моделі можуть використовувати. З часом агент збирає набір повторно використовуваних можливостей, розвиваючи потрібні йому \"інструменти\".\n\nПам'ятайте, що виконання коду додає складності. Запуск коду, згенерованого агентом, вимагає безпечного середовища з sandboxing, лімітами ресурсів і моніторингом. Ці вимоги створюють операційні витрати й міркування безпеки, яких немає у прямих викликах. Переваги виконання коду — менше токенів, нижча латентність і краща композиція інструментів — варто зважувати проти цих витрат.\n\nПідсумок\n\nMCP надає базовий протокол для підключення агентів до багатьох інструментів і систем. Але коли підключено надто багато серверів, визначення та результати можуть надмірно споживати токени, знижуючи ефективність агента.\n\nХоча багато з цих проблем здаються новими (керування контекстом, композиція інструментів, збереження стану), у розробці ПЗ є відомі рішення. Виконання коду застосовує ці патерни до агентів, дозволяючи використовувати знайомі програмні конструкції для ефективнішої роботи з серверами MCP. Якщо впроваджуєте цей підхід, поділіться результатами з MCP-спільнотою.\n\nПодяки\n\nЦю статтю написали Адам Джонс і Конор Келлі. Дякуємо Джеремі Фоксу, Джерому Своннаку, Стюарту Рітчі, Моллі Ворвек, Метту Семюелсу та Меґґі Во за відгуки до чернеток.",
      "edited": false
    }
  },
  "metadata": {
    "tags": [
      "Anthropic",
      "MCP",
      "Engineering"
    ]
  }
}